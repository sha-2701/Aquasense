{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrtjaUFf6FgZ",
        "outputId": "93656bbc-dd97-433e-b2c5-23f31a8975ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "# ========================================================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Data\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import tensorflow.image as tfi\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "# Data Visulization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model Layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU, ReLU\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Backbone\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Model Architecture Visualization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Optimizer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Callbacks\n",
        "from keras.callbacks import ModelCheckpoint, Callback\n",
        "import cv2\n",
        "# =====================================================\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *"
      ],
      "metadata": {
        "id": "hYbHpztg8kAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path: str, size: tuple = (256, 256), mask: bool = False):\n",
        "    image = load_img(path)\n",
        "    image = img_to_array(image)\n",
        "    image = cv2.resize(image, size)\n",
        "    # Move scaling after resizing\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    if mask:\n",
        "        image = image[:, :, :1]\n",
        "    return image"
      ],
      "metadata": {
        "id": "VCYw_CcV86KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(root_path:str):\n",
        "    image_paths = sorted(glob(os.path.join(root_path, \"Image/*.jpg\")))\n",
        "    mask_paths = [path.replace(\"Image\", \"Mask\").replace(\"jpg\", \"png\") for path in image_paths]\n",
        "\n",
        "    images = np.empty(shape=(len(image_paths), 256, 256, 3), dtype=np.float32)\n",
        "    masks = np.empty(shape=(len(image_paths), 256, 256, 1), dtype=np.float32)\n",
        "\n",
        "    for i, (img_path, mask_path) in enumerate(tqdm(zip(image_paths, mask_paths), desc=\"Loading\")):\n",
        "        images[i] = load_image(img_path, mask=False)\n",
        "        masks[i] = load_image(mask_path, mask=True)\n",
        "\n",
        "    return images, masks\n"
      ],
      "metadata": {
        "id": "VnFePSpm9GUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_image(image, angle, target_size=(256, 256)):\n",
        "    is_tensor = tf.is_tensor(image)\n",
        "    if is_tensor:\n",
        "        image = image.numpy()\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated_image = cv2.warpAffine(image, matrix, (w, h))\n",
        "\n",
        "    rotated_image = center_crop_or_pad(rotated_image, target_size)\n",
        "    if is_tensor:\n",
        "        rotated_image = tf.convert_to_tensor(rotated_image)\n",
        "\n",
        "    return rotated_image"
      ],
      "metadata": {
        "id": "_dox00M9bmwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def center_crop_or_pad(image, target_size):\n",
        "    h, w = image.shape[:2]\n",
        "    th, tw = target_size\n",
        "\n",
        "    x1 = max(0, (w - tw) // 2)\n",
        "    y1 = max(0, (h - th) // 2)\n",
        "    x2 = min(w, x1 + tw)\n",
        "    y2 = min(h, y1 + th)\n",
        "    image = image[y1:y2, x1:x2]\n",
        "\n",
        "    if image.shape[:2] != target_size:\n",
        "        pad_top = max(0, (th - h) // 2)\n",
        "        pad_bottom = max(0, th - h - pad_top)\n",
        "        pad_left = max(0, (tw - w) // 2)\n",
        "        pad_right = max(0, tw - w - pad_left)\n",
        "        padding = [(pad_top, pad_bottom), (pad_left, pad_right)]\n",
        "        if image.ndim == 3:\n",
        "            padding.append((0, 0))\n",
        "        image = np.pad(image, padding, mode='constant')\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "FXgJUaOLdZyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_and_augment_data(root_path:str, rotation_angles=(45, 90, 135, 180, 225, 270, 315, 360)):\n",
        "#     image_paths = sorted(glob(os.path.join(root_path, \"Image/*.jpg\")))\n",
        "#     mask_paths = [path.replace(\"Image\", \"Mask\").replace(\"jpg\", \"png\") for path in image_paths]\n",
        "\n",
        "#     images = []\n",
        "#     masks = []\n",
        "\n",
        "#     for i, (img_path, mask_path) in enumerate(tqdm(zip(image_paths, mask_paths), desc=\"Loading & Augmenting\")):\n",
        "#         original_image = load_image(img_path, mask=False)\n",
        "#         original_mask = load_image(mask_path, mask=True)\n",
        "\n",
        "\n",
        "#         for angle in rotation_angles:\n",
        "#             rotated_image = rotate_image(original_image, angle)\n",
        "#             rotated_mask = rotate_image(original_mask, angle)\n",
        "#             images.append(rotated_image)\n",
        "#             masks.append(rotated_mask)\n",
        "\n",
        "#     all_images = np.array(images)\n",
        "#     all_masks = np.array(masks)\n",
        "#     return all_images, all_masks\n",
        "\n",
        "def load_and_augment_data(root_path: str, rotation_angles=(45, 90, 135, 180, 225, 270, 315, 360)):\n",
        "    image_paths = sorted(glob(os.path.join(root_path, \"Image/*.jpg\")))\n",
        "    mask_paths = [path.replace(\"Image\", \"Mask\").replace(\"jpg\", \"png\") for path in image_paths]\n",
        "\n",
        "    original_images = np.array([load_image(path, mask=False) for path in image_paths])\n",
        "    original_masks = np.array([load_image(path, mask=True) for path in mask_paths])\n",
        "\n",
        "    train_images, val_test_images, train_masks, val_test_masks = train_test_split(\n",
        "    original_images, original_masks, test_size=0.2, shuffle=False)\n",
        "    val_images, test_images, val_masks, test_masks = train_test_split(\n",
        "    val_test_images, val_test_masks, test_size=0.5, shuffle=False )\n",
        "\n",
        "    train_masks = np.squeeze(train_masks, axis=3)\n",
        "    val_masks = np.squeeze(val_masks, axis=3)\n",
        "    test_masks = np.squeeze(test_masks, axis=3)\n",
        "    augmented_images = []\n",
        "    augmented_masks = []\n",
        "    for img, msk in zip(train_images, train_masks):\n",
        "        for angle in rotation_angles:\n",
        "            rotated_image = rotate_image(img, angle)\n",
        "            rotated_mask = rotate_image(msk, angle)\n",
        "            augmented_images.append(rotated_image)\n",
        "            augmented_masks.append(rotated_mask)\n",
        "\n",
        "    train_images = np.concatenate([train_images, np.array(augmented_images)], axis=0)\n",
        "    train_masks = np.concatenate([train_masks, np.array(augmented_masks)], axis=0)\n",
        "\n",
        "    return train_images,val_images, test_images, train_masks,val_masks, test_masks"
      ],
      "metadata": {
        "id": "nGNtahniMbDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, val_images,test_images, train_masks, val_masks , test_masks= load_and_augment_data(\"/content/drive/MyDrive/flood\")"
      ],
      "metadata": {
        "id": "O9HhXEfHMvX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2k-qH1Fy-3p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZT6NqEn4kcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fdb1g4TX5nkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images, masks, n_images, SIZE=(15,8)) -> None:\n",
        "    for i in range(n_images):\n",
        "        plt.figure(figsize=SIZE)\n",
        "        id = np.random.randint(len(images))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(images[id])\n",
        "        plt.title(\"Image\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot the Mask\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(masks[id], cmap='gray')\n",
        "        plt.title(\"Mask\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot the Overlapping Mask\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(images[id], cmap='gray')\n",
        "        plt.imshow(masks[id], cmap='gray', alpha=0.5)\n",
        "        plt.title(\"Overlapping Mask\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Shwo a Single Frame : This is done to speed up plotting for large number images\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "TGkwgYa9_q2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(train_images, train_masks, n_images=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zh9KEIoR_vuI",
        "outputId": "442ebdfb-0b15-40fd-baac-150390373bca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (256, 256, 3)\n",
        "def unet(sz=image_size):\n",
        "    x = Input(sz)\n",
        "    inputs = x\n",
        "\n",
        "    #downsampling\n",
        "    f = 8 #number of filters\n",
        "    layers = []\n",
        "    for i in range(6):\n",
        "        x = Conv2D(f, 3, activation='relu',padding='same')(x)\n",
        "        x = Conv2D(f, 3, activation='relu',padding='same')(x)\n",
        "        layers.append(x)\n",
        "        x = MaxPooling2D()(x)\n",
        "        f = f*2\n",
        "    ff2 = 64\n",
        "\n",
        "    #bottleneck\n",
        "    j = len(layers)-1\n",
        "    x = Conv2D(f, 3, activation='relu',padding='same')(x)\n",
        "    x = Conv2D(f, 3, activation='relu',padding='same')(x)\n",
        "    x = Conv2DTranspose(ff2, 2, strides=(2,2),padding='same')(x)\n",
        "    x = Concatenate(axis=3)([x,layers[j]])\n",
        "    j = j-1\n",
        "\n",
        "    #upsampling\n",
        "    for i in range(5):\n",
        "        ff2 = ff2//2\n",
        "        f = f//2\n",
        "        x = Conv2D(f, 3, activation='relu',padding='same')(x)\n",
        "        x = Conv2D(f, 3, activation='relu',padding='same')(x)\n",
        "        x = Conv2DTranspose(ff2, 2, strides=(2,2),padding='same')(x)\n",
        "        x = Concatenate(axis=3)([x,layers[j]])\n",
        "        j = j-1\n",
        "    #classification\n",
        "    x = Conv2D(f, 3, activation='relu',padding='same')(x)\n",
        "    x = Conv2D(f, 3, activation='relu',padding='same')(x)\n",
        "    outputs = Conv2D(1, 1, activation = 'sigmoid')(x)\n",
        "    model = Model(inputs=[inputs], outputs = [outputs])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "iCAYqBQxGZ5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet()"
      ],
      "metadata": {
        "id": "-6G46q4yBgQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUJyKYmoBnLd",
        "outputId": "6c3f46a2-8f91-4e0c-e559-511f6caebe2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 8)          224       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 8)          584       ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 8)          0         ['conv2d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 16)         1168      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 16)         2320      ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 16)           0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 32)           4640      ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 32)           9248      ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 32)           0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 64)           18496     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 64)           36928     ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)           0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 128)          73856     ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 128)          147584    ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 128)            0         ['conv2d_9[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 256)            295168    ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 256)            590080    ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 256)            0         ['conv2d_11[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 512)            1180160   ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 4, 4, 512)            2359808   ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 64)             131136    ['conv2d_13[0][0]']           \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8, 8, 320)            0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     'conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 256)            737536    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 256)            590080    ['conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 32)           32800     ['conv2d_15[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 16, 16, 160)          0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 128)          184448    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 16, 16, 128)          147584    ['conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 16)           8208      ['conv2d_17[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 32, 32, 80)           0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   'conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 64)           46144     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 64, 64, 8)            2056      ['conv2d_19[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 64, 64, 40)           0         ['conv2d_transpose_3[0][0]',  \n",
            " )                                                                   'conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 64, 64, 32)           11552     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 64, 64, 32)           9248      ['conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 128, 128, 4)          516       ['conv2d_21[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 128, 128, 20)         0         ['conv2d_transpose_4[0][0]',  \n",
            " )                                                                   'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 128, 128, 16)         2896      ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 128, 128, 16)         2320      ['conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 256, 256, 2)          130       ['conv2d_23[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 256, 256, 10)         0         ['conv2d_transpose_5[0][0]',  \n",
            " )                                                                   'conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 256, 256, 16)         1456      ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 256, 256, 16)         2320      ['conv2d_24[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 256, 256, 1)          17        ['conv2d_25[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6667639 (25.44 MB)\n",
            "Trainable params: 6667639 (25.44 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "j3K28PdMBrOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def IoU(y_true, y_pred, smooth=1):\n",
        "  # Convert masks to binary format before calculations\n",
        "  y_true = tf.cast(y_true > 0.5, tf.float32)\n",
        "  y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2])\n",
        "  sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=[1,2])\n",
        "  jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "  return K.mean(jac)"
      ],
      "metadata": {
        "id": "cyApGyTOgAY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true > 0.5, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "metadata": {
        "id": "pncKFix7gjGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true > 0.5, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "metadata": {
        "id": "t8i7iHVqj8_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    f1 = 2 * ((p * r) / (p + r + K.epsilon()))\n",
        "    return f1"
      ],
      "metadata": {
        "id": "M2KToWzqg16A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true = tf.cast(y_true > 0.5, tf.float32)  # Convert to binary\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)  # Convert to binary\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n"
      ],
      "metadata": {
        "id": "cYrZ5AMog7yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true > 0.5, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n"
      ],
      "metadata": {
        "id": "9eaz4OVpHZF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\n",
        "        \"accuracy\",\n",
        "        IoU,\n",
        "        dice_coef,\n",
        "        precision,\n",
        "        recall,\n",
        "        f1_score\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Jxp7h2iODy4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = []\n",
        "accuracy_values = []\n",
        "iou_values = []\n",
        "dice_values = []\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "jaccard_values = []"
      ],
      "metadata": {
        "id": "_c_VNKRuhRRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(\"final_Unet_model_75.h5\", save_best_only=True),\n",
        "]"
      ],
      "metadata": {
        "id": "pN8gf49lHFJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history =  model.fit(\n",
        "    train_images, train_masks,\n",
        "    validation_data=(test_images, test_masks),\n",
        "    epochs=100,\n",
        "    callbacks=callbacks,\n",
        "    batch_size=10,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_Y89nRfD4AU",
        "outputId": "5eaa4bec-fe12-415b-88c4-e79289a3ffd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "208/208 [==============================] - 12s 56ms/step - loss: 0.3470 - accuracy: 0.8289 - IoU: 0.6485 - dice_coef: 0.7985 - precision: 0.8349 - recall: 0.7736 - f1_score: 0.7985 - val_loss: 0.2779 - val_accuracy: 0.8805 - val_IoU: 0.7360 - val_dice_coef: 0.8588 - val_precision: 0.8414 - val_recall: 0.8778 - val_f1_score: 0.8588\n",
            "Epoch 2/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.3444 - accuracy: 0.8309 - IoU: 0.6494 - dice_coef: 0.8012 - precision: 0.8373 - recall: 0.7782 - f1_score: 0.8012 - val_loss: 0.2652 - val_accuracy: 0.8802 - val_IoU: 0.7266 - val_dice_coef: 0.8611 - val_precision: 0.8724 - val_recall: 0.8508 - val_f1_score: 0.8611\n",
            "Epoch 3/100\n",
            "208/208 [==============================] - 12s 56ms/step - loss: 0.3385 - accuracy: 0.8353 - IoU: 0.6570 - dice_coef: 0.8074 - precision: 0.8446 - recall: 0.7843 - f1_score: 0.8074 - val_loss: 0.2679 - val_accuracy: 0.8813 - val_IoU: 0.7485 - val_dice_coef: 0.8663 - val_precision: 0.8111 - val_recall: 0.9303 - val_f1_score: 0.8663\n",
            "Epoch 4/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.3110 - accuracy: 0.8516 - IoU: 0.6850 - dice_coef: 0.8291 - precision: 0.8630 - recall: 0.8037 - f1_score: 0.8291 - val_loss: 0.2613 - val_accuracy: 0.8875 - val_IoU: 0.7555 - val_dice_coef: 0.8706 - val_precision: 0.8377 - val_recall: 0.9070 - val_f1_score: 0.8706\n",
            "Epoch 5/100\n",
            "208/208 [==============================] - 12s 58ms/step - loss: 0.2977 - accuracy: 0.8580 - IoU: 0.6967 - dice_coef: 0.8385 - precision: 0.8696 - recall: 0.8138 - f1_score: 0.8385 - val_loss: 0.2299 - val_accuracy: 0.8952 - val_IoU: 0.7614 - val_dice_coef: 0.8806 - val_precision: 0.8590 - val_recall: 0.9034 - val_f1_score: 0.8806\n",
            "Epoch 6/100\n",
            "208/208 [==============================] - 12s 58ms/step - loss: 0.2919 - accuracy: 0.8602 - IoU: 0.7008 - dice_coef: 0.8406 - precision: 0.8707 - recall: 0.8168 - f1_score: 0.8406 - val_loss: 0.2230 - val_accuracy: 0.8997 - val_IoU: 0.7512 - val_dice_coef: 0.8748 - val_precision: 0.9275 - val_recall: 0.8282 - val_f1_score: 0.8748\n",
            "Epoch 7/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2837 - accuracy: 0.8638 - IoU: 0.7092 - dice_coef: 0.8476 - precision: 0.8756 - recall: 0.8246 - f1_score: 0.8476 - val_loss: 0.2321 - val_accuracy: 0.8938 - val_IoU: 0.7573 - val_dice_coef: 0.8752 - val_precision: 0.8721 - val_recall: 0.8785 - val_f1_score: 0.8752\n",
            "Epoch 8/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2768 - accuracy: 0.8662 - IoU: 0.7133 - dice_coef: 0.8507 - precision: 0.8788 - recall: 0.8279 - f1_score: 0.8507 - val_loss: 0.2255 - val_accuracy: 0.9008 - val_IoU: 0.7753 - val_dice_coef: 0.8863 - val_precision: 0.8715 - val_recall: 0.9017 - val_f1_score: 0.8863\n",
            "Epoch 9/100\n",
            "208/208 [==============================] - 12s 59ms/step - loss: 0.2730 - accuracy: 0.8676 - IoU: 0.7175 - dice_coef: 0.8537 - precision: 0.8806 - recall: 0.8324 - f1_score: 0.8537 - val_loss: 0.2214 - val_accuracy: 0.9006 - val_IoU: 0.7657 - val_dice_coef: 0.8826 - val_precision: 0.9019 - val_recall: 0.8646 - val_f1_score: 0.8826\n",
            "Epoch 10/100\n",
            "208/208 [==============================] - 12s 59ms/step - loss: 0.2632 - accuracy: 0.8715 - IoU: 0.7257 - dice_coef: 0.8583 - precision: 0.8840 - recall: 0.8368 - f1_score: 0.8583 - val_loss: 0.2069 - val_accuracy: 0.9035 - val_IoU: 0.7695 - val_dice_coef: 0.8853 - val_precision: 0.9031 - val_recall: 0.8683 - val_f1_score: 0.8853\n",
            "Epoch 11/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2556 - accuracy: 0.8748 - IoU: 0.7330 - dice_coef: 0.8624 - precision: 0.8859 - recall: 0.8426 - f1_score: 0.8624 - val_loss: 0.2167 - val_accuracy: 0.8984 - val_IoU: 0.7729 - val_dice_coef: 0.8850 - val_precision: 0.8667 - val_recall: 0.9046 - val_f1_score: 0.8850\n",
            "Epoch 12/100\n",
            "208/208 [==============================] - 12s 59ms/step - loss: 0.2536 - accuracy: 0.8763 - IoU: 0.7366 - dice_coef: 0.8643 - precision: 0.8872 - recall: 0.8449 - f1_score: 0.8643 - val_loss: 0.2018 - val_accuracy: 0.9070 - val_IoU: 0.7877 - val_dice_coef: 0.8940 - val_precision: 0.8726 - val_recall: 0.9168 - val_f1_score: 0.8940\n",
            "Epoch 13/100\n",
            "208/208 [==============================] - 12s 56ms/step - loss: 0.2491 - accuracy: 0.8778 - IoU: 0.7407 - dice_coef: 0.8674 - precision: 0.8903 - recall: 0.8482 - f1_score: 0.8674 - val_loss: 0.2175 - val_accuracy: 0.9037 - val_IoU: 0.7839 - val_dice_coef: 0.8904 - val_precision: 0.8625 - val_recall: 0.9207 - val_f1_score: 0.8904\n",
            "Epoch 14/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2439 - accuracy: 0.8799 - IoU: 0.7440 - dice_coef: 0.8697 - precision: 0.8918 - recall: 0.8505 - f1_score: 0.8697 - val_loss: 0.2655 - val_accuracy: 0.8885 - val_IoU: 0.7623 - val_dice_coef: 0.8759 - val_precision: 0.8307 - val_recall: 0.9265 - val_f1_score: 0.8759\n",
            "Epoch 15/100\n",
            "208/208 [==============================] - 12s 58ms/step - loss: 0.2437 - accuracy: 0.8805 - IoU: 0.7461 - dice_coef: 0.8707 - precision: 0.8927 - recall: 0.8518 - f1_score: 0.8707 - val_loss: 0.1788 - val_accuracy: 0.9136 - val_IoU: 0.7964 - val_dice_coef: 0.9009 - val_precision: 0.9083 - val_recall: 0.8936 - val_f1_score: 0.9009\n",
            "Epoch 16/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2364 - accuracy: 0.8837 - IoU: 0.7545 - dice_coef: 0.8749 - precision: 0.8949 - recall: 0.8577 - f1_score: 0.8749 - val_loss: 0.1935 - val_accuracy: 0.9147 - val_IoU: 0.8044 - val_dice_coef: 0.9052 - val_precision: 0.8954 - val_recall: 0.9155 - val_f1_score: 0.9052\n",
            "Epoch 17/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2388 - accuracy: 0.8826 - IoU: 0.7524 - dice_coef: 0.8739 - precision: 0.8940 - recall: 0.8565 - f1_score: 0.8739 - val_loss: 0.2025 - val_accuracy: 0.9023 - val_IoU: 0.7623 - val_dice_coef: 0.8816 - val_precision: 0.9221 - val_recall: 0.8448 - val_f1_score: 0.8816\n",
            "Epoch 18/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2320 - accuracy: 0.8856 - IoU: 0.7588 - dice_coef: 0.8780 - precision: 0.8980 - recall: 0.8608 - f1_score: 0.8780 - val_loss: 0.2240 - val_accuracy: 0.9032 - val_IoU: 0.7871 - val_dice_coef: 0.8911 - val_precision: 0.8702 - val_recall: 0.9132 - val_f1_score: 0.8911\n",
            "Epoch 19/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2272 - accuracy: 0.8872 - IoU: 0.7624 - dice_coef: 0.8805 - precision: 0.9005 - recall: 0.8634 - f1_score: 0.8805 - val_loss: 0.1894 - val_accuracy: 0.9112 - val_IoU: 0.7987 - val_dice_coef: 0.8996 - val_precision: 0.8895 - val_recall: 0.9100 - val_f1_score: 0.8996\n",
            "Epoch 20/100\n",
            "208/208 [==============================] - 12s 56ms/step - loss: 0.2202 - accuracy: 0.8900 - IoU: 0.7694 - dice_coef: 0.8844 - precision: 0.9025 - recall: 0.8687 - f1_score: 0.8844 - val_loss: 0.2073 - val_accuracy: 0.9092 - val_IoU: 0.7957 - val_dice_coef: 0.8973 - val_precision: 0.8795 - val_recall: 0.9158 - val_f1_score: 0.8973\n",
            "Epoch 21/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2205 - accuracy: 0.8899 - IoU: 0.7697 - dice_coef: 0.8842 - precision: 0.9014 - recall: 0.8692 - f1_score: 0.8842 - val_loss: 0.2000 - val_accuracy: 0.9113 - val_IoU: 0.7962 - val_dice_coef: 0.9007 - val_precision: 0.8906 - val_recall: 0.9112 - val_f1_score: 0.9007\n",
            "Epoch 22/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2124 - accuracy: 0.8934 - IoU: 0.7781 - dice_coef: 0.8890 - precision: 0.9066 - recall: 0.8733 - f1_score: 0.8890 - val_loss: 0.1818 - val_accuracy: 0.9146 - val_IoU: 0.8020 - val_dice_coef: 0.9035 - val_precision: 0.8969 - val_recall: 0.9103 - val_f1_score: 0.9035\n",
            "Epoch 23/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2147 - accuracy: 0.8924 - IoU: 0.7757 - dice_coef: 0.8876 - precision: 0.9046 - recall: 0.8725 - f1_score: 0.8876 - val_loss: 0.1928 - val_accuracy: 0.9112 - val_IoU: 0.7949 - val_dice_coef: 0.8999 - val_precision: 0.8848 - val_recall: 0.9157 - val_f1_score: 0.8999\n",
            "Epoch 24/100\n",
            "208/208 [==============================] - 12s 58ms/step - loss: 0.2137 - accuracy: 0.8929 - IoU: 0.7767 - dice_coef: 0.8887 - precision: 0.9046 - recall: 0.8749 - f1_score: 0.8887 - val_loss: 0.1713 - val_accuracy: 0.9177 - val_IoU: 0.8005 - val_dice_coef: 0.9055 - val_precision: 0.9271 - val_recall: 0.8850 - val_f1_score: 0.9055\n",
            "Epoch 25/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.2040 - accuracy: 0.8968 - IoU: 0.7859 - dice_coef: 0.8933 - precision: 0.9093 - recall: 0.8791 - f1_score: 0.8933 - val_loss: 0.1884 - val_accuracy: 0.9135 - val_IoU: 0.8061 - val_dice_coef: 0.9047 - val_precision: 0.8802 - val_recall: 0.9309 - val_f1_score: 0.9047\n",
            "Epoch 26/100\n",
            "208/208 [==============================] - 12s 56ms/step - loss: 0.2094 - accuracy: 0.8943 - IoU: 0.7805 - dice_coef: 0.8904 - precision: 0.9058 - recall: 0.8771 - f1_score: 0.8904 - val_loss: 0.1874 - val_accuracy: 0.9116 - val_IoU: 0.7999 - val_dice_coef: 0.9030 - val_precision: 0.8714 - val_recall: 0.9372 - val_f1_score: 0.9030\n",
            "Epoch 27/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1989 - accuracy: 0.8986 - IoU: 0.7906 - dice_coef: 0.8961 - precision: 0.9105 - recall: 0.8832 - f1_score: 0.8961 - val_loss: 0.1887 - val_accuracy: 0.9124 - val_IoU: 0.7957 - val_dice_coef: 0.9026 - val_precision: 0.8847 - val_recall: 0.9214 - val_f1_score: 0.9026\n",
            "Epoch 28/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1945 - accuracy: 0.8998 - IoU: 0.7936 - dice_coef: 0.8974 - precision: 0.9111 - recall: 0.8851 - f1_score: 0.8974 - val_loss: 0.1978 - val_accuracy: 0.9076 - val_IoU: 0.7977 - val_dice_coef: 0.8996 - val_precision: 0.8563 - val_recall: 0.9483 - val_f1_score: 0.8996\n",
            "Epoch 29/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1858 - accuracy: 0.9031 - IoU: 0.8018 - dice_coef: 0.9030 - precision: 0.9147 - recall: 0.8921 - f1_score: 0.9030 - val_loss: 0.1932 - val_accuracy: 0.9156 - val_IoU: 0.8069 - val_dice_coef: 0.9069 - val_precision: 0.8838 - val_recall: 0.9315 - val_f1_score: 0.9069\n",
            "Epoch 30/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1829 - accuracy: 0.9037 - IoU: 0.8033 - dice_coef: 0.9039 - precision: 0.9158 - recall: 0.8932 - f1_score: 0.9039 - val_loss: 0.2126 - val_accuracy: 0.9052 - val_IoU: 0.7886 - val_dice_coef: 0.8943 - val_precision: 0.8566 - val_recall: 0.9361 - val_f1_score: 0.8943\n",
            "Epoch 31/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1772 - accuracy: 0.9059 - IoU: 0.8087 - dice_coef: 0.9068 - precision: 0.9175 - recall: 0.8969 - f1_score: 0.9068 - val_loss: 0.1742 - val_accuracy: 0.9169 - val_IoU: 0.8011 - val_dice_coef: 0.9061 - val_precision: 0.9082 - val_recall: 0.9040 - val_f1_score: 0.9061\n",
            "Epoch 32/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1779 - accuracy: 0.9057 - IoU: 0.8075 - dice_coef: 0.9060 - precision: 0.9168 - recall: 0.8964 - f1_score: 0.9060 - val_loss: 0.1788 - val_accuracy: 0.9151 - val_IoU: 0.8058 - val_dice_coef: 0.9056 - val_precision: 0.8812 - val_recall: 0.9315 - val_f1_score: 0.9056\n",
            "Epoch 33/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1641 - accuracy: 0.9107 - IoU: 0.8210 - dice_coef: 0.9135 - precision: 0.9221 - recall: 0.9056 - f1_score: 0.9135 - val_loss: 0.1794 - val_accuracy: 0.9162 - val_IoU: 0.8094 - val_dice_coef: 0.9084 - val_precision: 0.8896 - val_recall: 0.9283 - val_f1_score: 0.9084\n",
            "Epoch 34/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1600 - accuracy: 0.9121 - IoU: 0.8245 - dice_coef: 0.9153 - precision: 0.9230 - recall: 0.9082 - f1_score: 0.9153 - val_loss: 0.1987 - val_accuracy: 0.9087 - val_IoU: 0.7959 - val_dice_coef: 0.8987 - val_precision: 0.8656 - val_recall: 0.9351 - val_f1_score: 0.8987\n",
            "Epoch 35/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1550 - accuracy: 0.9136 - IoU: 0.8281 - dice_coef: 0.9171 - precision: 0.9243 - recall: 0.9104 - f1_score: 0.9171 - val_loss: 0.1765 - val_accuracy: 0.9162 - val_IoU: 0.8054 - val_dice_coef: 0.9070 - val_precision: 0.8918 - val_recall: 0.9230 - val_f1_score: 0.9070\n",
            "Epoch 36/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1752 - accuracy: 0.9064 - IoU: 0.8104 - dice_coef: 0.9076 - precision: 0.9172 - recall: 0.8992 - f1_score: 0.9076 - val_loss: 0.1863 - val_accuracy: 0.9137 - val_IoU: 0.8003 - val_dice_coef: 0.9035 - val_precision: 0.8848 - val_recall: 0.9231 - val_f1_score: 0.9035\n",
            "Epoch 37/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1626 - accuracy: 0.9109 - IoU: 0.8209 - dice_coef: 0.9136 - precision: 0.9221 - recall: 0.9059 - f1_score: 0.9136 - val_loss: 0.1937 - val_accuracy: 0.9127 - val_IoU: 0.8021 - val_dice_coef: 0.9035 - val_precision: 0.8817 - val_recall: 0.9266 - val_f1_score: 0.9035\n",
            "Epoch 38/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1481 - accuracy: 0.9160 - IoU: 0.8347 - dice_coef: 0.9210 - precision: 0.9259 - recall: 0.9165 - f1_score: 0.9210 - val_loss: 0.1963 - val_accuracy: 0.9119 - val_IoU: 0.7954 - val_dice_coef: 0.9027 - val_precision: 0.8754 - val_recall: 0.9319 - val_f1_score: 0.9027\n",
            "Epoch 39/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1412 - accuracy: 0.9185 - IoU: 0.8407 - dice_coef: 0.9244 - precision: 0.9292 - recall: 0.9200 - f1_score: 0.9244 - val_loss: 0.1921 - val_accuracy: 0.9146 - val_IoU: 0.8004 - val_dice_coef: 0.9053 - val_precision: 0.8883 - val_recall: 0.9231 - val_f1_score: 0.9053\n",
            "Epoch 40/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1381 - accuracy: 0.9195 - IoU: 0.8432 - dice_coef: 0.9256 - precision: 0.9301 - recall: 0.9216 - f1_score: 0.9256 - val_loss: 0.2136 - val_accuracy: 0.9100 - val_IoU: 0.7934 - val_dice_coef: 0.8990 - val_precision: 0.8768 - val_recall: 0.9228 - val_f1_score: 0.8990\n",
            "Epoch 41/100\n",
            "208/208 [==============================] - 12s 56ms/step - loss: 0.1363 - accuracy: 0.9201 - IoU: 0.8451 - dice_coef: 0.9267 - precision: 0.9305 - recall: 0.9232 - f1_score: 0.9267 - val_loss: 0.1924 - val_accuracy: 0.9147 - val_IoU: 0.8022 - val_dice_coef: 0.9067 - val_precision: 0.8832 - val_recall: 0.9317 - val_f1_score: 0.9067\n",
            "Epoch 42/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1310 - accuracy: 0.9221 - IoU: 0.8507 - dice_coef: 0.9293 - precision: 0.9323 - recall: 0.9266 - f1_score: 0.9293 - val_loss: 0.1936 - val_accuracy: 0.9144 - val_IoU: 0.8007 - val_dice_coef: 0.9052 - val_precision: 0.8868 - val_recall: 0.9247 - val_f1_score: 0.9052\n",
            "Epoch 43/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1273 - accuracy: 0.9235 - IoU: 0.8535 - dice_coef: 0.9314 - precision: 0.9344 - recall: 0.9286 - f1_score: 0.9314 - val_loss: 0.2006 - val_accuracy: 0.9122 - val_IoU: 0.7992 - val_dice_coef: 0.9023 - val_precision: 0.8840 - val_recall: 0.9216 - val_f1_score: 0.9023\n",
            "Epoch 44/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1249 - accuracy: 0.9245 - IoU: 0.8561 - dice_coef: 0.9328 - precision: 0.9357 - recall: 0.9301 - f1_score: 0.9328 - val_loss: 0.2052 - val_accuracy: 0.9116 - val_IoU: 0.7975 - val_dice_coef: 0.9020 - val_precision: 0.8776 - val_recall: 0.9281 - val_f1_score: 0.9020\n",
            "Epoch 45/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1291 - accuracy: 0.9230 - IoU: 0.8521 - dice_coef: 0.9305 - precision: 0.9344 - recall: 0.9270 - f1_score: 0.9305 - val_loss: 0.1967 - val_accuracy: 0.9149 - val_IoU: 0.7993 - val_dice_coef: 0.9044 - val_precision: 0.8978 - val_recall: 0.9112 - val_f1_score: 0.9044\n",
            "Epoch 46/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1333 - accuracy: 0.9211 - IoU: 0.8467 - dice_coef: 0.9277 - precision: 0.9327 - recall: 0.9233 - f1_score: 0.9277 - val_loss: 0.1981 - val_accuracy: 0.9143 - val_IoU: 0.8015 - val_dice_coef: 0.9044 - val_precision: 0.8845 - val_recall: 0.9256 - val_f1_score: 0.9044\n",
            "Epoch 47/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1999 - accuracy: 0.8962 - IoU: 0.7888 - dice_coef: 0.8940 - precision: 0.9036 - recall: 0.8866 - f1_score: 0.8940 - val_loss: 0.1957 - val_accuracy: 0.9121 - val_IoU: 0.7957 - val_dice_coef: 0.9030 - val_precision: 0.8758 - val_recall: 0.9320 - val_f1_score: 0.9030\n",
            "Epoch 48/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1284 - accuracy: 0.9232 - IoU: 0.8522 - dice_coef: 0.9305 - precision: 0.9345 - recall: 0.9268 - f1_score: 0.9305 - val_loss: 0.1913 - val_accuracy: 0.9158 - val_IoU: 0.8039 - val_dice_coef: 0.9057 - val_precision: 0.8988 - val_recall: 0.9128 - val_f1_score: 0.9057\n",
            "Epoch 49/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1183 - accuracy: 0.9270 - IoU: 0.8628 - dice_coef: 0.9362 - precision: 0.9385 - recall: 0.9340 - f1_score: 0.9362 - val_loss: 0.1917 - val_accuracy: 0.9154 - val_IoU: 0.7995 - val_dice_coef: 0.9054 - val_precision: 0.8955 - val_recall: 0.9155 - val_f1_score: 0.9054\n",
            "Epoch 50/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1133 - accuracy: 0.9288 - IoU: 0.8680 - dice_coef: 0.9387 - precision: 0.9402 - recall: 0.9373 - f1_score: 0.9387 - val_loss: 0.1976 - val_accuracy: 0.9142 - val_IoU: 0.8002 - val_dice_coef: 0.9050 - val_precision: 0.8820 - val_recall: 0.9297 - val_f1_score: 0.9050\n",
            "Epoch 51/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1099 - accuracy: 0.9300 - IoU: 0.8714 - dice_coef: 0.9404 - precision: 0.9417 - recall: 0.9392 - f1_score: 0.9404 - val_loss: 0.2102 - val_accuracy: 0.9113 - val_IoU: 0.7957 - val_dice_coef: 0.9014 - val_precision: 0.8724 - val_recall: 0.9328 - val_f1_score: 0.9014\n",
            "Epoch 52/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1090 - accuracy: 0.9304 - IoU: 0.8721 - dice_coef: 0.9409 - precision: 0.9424 - recall: 0.9395 - f1_score: 0.9409 - val_loss: 0.2137 - val_accuracy: 0.9113 - val_IoU: 0.7905 - val_dice_coef: 0.9006 - val_precision: 0.8805 - val_recall: 0.9220 - val_f1_score: 0.9006\n",
            "Epoch 53/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1067 - accuracy: 0.9312 - IoU: 0.8749 - dice_coef: 0.9421 - precision: 0.9432 - recall: 0.9410 - f1_score: 0.9421 - val_loss: 0.2018 - val_accuracy: 0.9132 - val_IoU: 0.8018 - val_dice_coef: 0.9041 - val_precision: 0.8778 - val_recall: 0.9325 - val_f1_score: 0.9041\n",
            "Epoch 54/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1053 - accuracy: 0.9318 - IoU: 0.8761 - dice_coef: 0.9427 - precision: 0.9438 - recall: 0.9418 - f1_score: 0.9427 - val_loss: 0.2139 - val_accuracy: 0.9074 - val_IoU: 0.7883 - val_dice_coef: 0.8969 - val_precision: 0.8624 - val_recall: 0.9350 - val_f1_score: 0.8969\n",
            "Epoch 55/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1336 - accuracy: 0.9211 - IoU: 0.8466 - dice_coef: 0.9273 - precision: 0.9319 - recall: 0.9232 - f1_score: 0.9273 - val_loss: 0.2059 - val_accuracy: 0.9107 - val_IoU: 0.7903 - val_dice_coef: 0.8994 - val_precision: 0.8848 - val_recall: 0.9146 - val_f1_score: 0.8994\n",
            "Epoch 56/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1114 - accuracy: 0.9294 - IoU: 0.8698 - dice_coef: 0.9395 - precision: 0.9415 - recall: 0.9377 - f1_score: 0.9395 - val_loss: 0.2166 - val_accuracy: 0.9091 - val_IoU: 0.7913 - val_dice_coef: 0.8985 - val_precision: 0.8709 - val_recall: 0.9280 - val_f1_score: 0.8985\n",
            "Epoch 57/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1049 - accuracy: 0.9319 - IoU: 0.8766 - dice_coef: 0.9429 - precision: 0.9441 - recall: 0.9418 - f1_score: 0.9429 - val_loss: 0.2229 - val_accuracy: 0.9115 - val_IoU: 0.7910 - val_dice_coef: 0.8995 - val_precision: 0.8878 - val_recall: 0.9115 - val_f1_score: 0.8995\n",
            "Epoch 58/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1031 - accuracy: 0.9326 - IoU: 0.8785 - dice_coef: 0.9439 - precision: 0.9450 - recall: 0.9429 - f1_score: 0.9439 - val_loss: 0.2219 - val_accuracy: 0.9111 - val_IoU: 0.7916 - val_dice_coef: 0.8989 - val_precision: 0.8915 - val_recall: 0.9067 - val_f1_score: 0.8989\n",
            "Epoch 59/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1004 - accuracy: 0.9336 - IoU: 0.8816 - dice_coef: 0.9452 - precision: 0.9461 - recall: 0.9444 - f1_score: 0.9452 - val_loss: 0.2268 - val_accuracy: 0.9108 - val_IoU: 0.7939 - val_dice_coef: 0.9002 - val_precision: 0.8751 - val_recall: 0.9270 - val_f1_score: 0.9002\n",
            "Epoch 60/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0990 - accuracy: 0.9342 - IoU: 0.8831 - dice_coef: 0.9462 - precision: 0.9471 - recall: 0.9454 - f1_score: 0.9462 - val_loss: 0.2203 - val_accuracy: 0.9107 - val_IoU: 0.7916 - val_dice_coef: 0.9001 - val_precision: 0.8791 - val_recall: 0.9224 - val_f1_score: 0.9001\n",
            "Epoch 61/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1008 - accuracy: 0.9336 - IoU: 0.8810 - dice_coef: 0.9451 - precision: 0.9464 - recall: 0.9440 - f1_score: 0.9451 - val_loss: 0.2246 - val_accuracy: 0.9119 - val_IoU: 0.7916 - val_dice_coef: 0.9007 - val_precision: 0.8808 - val_recall: 0.9218 - val_f1_score: 0.9007\n",
            "Epoch 62/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1001 - accuracy: 0.9338 - IoU: 0.8818 - dice_coef: 0.9456 - precision: 0.9466 - recall: 0.9448 - f1_score: 0.9456 - val_loss: 0.2141 - val_accuracy: 0.9130 - val_IoU: 0.7962 - val_dice_coef: 0.9029 - val_precision: 0.8839 - val_recall: 0.9230 - val_f1_score: 0.9029\n",
            "Epoch 63/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0992 - accuracy: 0.9340 - IoU: 0.8826 - dice_coef: 0.9462 - precision: 0.9472 - recall: 0.9453 - f1_score: 0.9462 - val_loss: 0.2348 - val_accuracy: 0.9072 - val_IoU: 0.7858 - val_dice_coef: 0.8953 - val_precision: 0.8735 - val_recall: 0.9183 - val_f1_score: 0.8953\n",
            "Epoch 64/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0991 - accuracy: 0.9342 - IoU: 0.8828 - dice_coef: 0.9459 - precision: 0.9470 - recall: 0.9450 - f1_score: 0.9459 - val_loss: 0.2362 - val_accuracy: 0.9103 - val_IoU: 0.7913 - val_dice_coef: 0.8982 - val_precision: 0.8853 - val_recall: 0.9116 - val_f1_score: 0.8982\n",
            "Epoch 65/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0971 - accuracy: 0.9349 - IoU: 0.8850 - dice_coef: 0.9472 - precision: 0.9481 - recall: 0.9465 - f1_score: 0.9472 - val_loss: 0.2436 - val_accuracy: 0.9094 - val_IoU: 0.7878 - val_dice_coef: 0.8978 - val_precision: 0.8777 - val_recall: 0.9192 - val_f1_score: 0.8978\n",
            "Epoch 66/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0962 - accuracy: 0.9352 - IoU: 0.8860 - dice_coef: 0.9475 - precision: 0.9484 - recall: 0.9467 - f1_score: 0.9475 - val_loss: 0.2225 - val_accuracy: 0.9131 - val_IoU: 0.7947 - val_dice_coef: 0.9026 - val_precision: 0.8901 - val_recall: 0.9154 - val_f1_score: 0.9026\n",
            "Epoch 67/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0989 - accuracy: 0.9342 - IoU: 0.8831 - dice_coef: 0.9463 - precision: 0.9473 - recall: 0.9454 - f1_score: 0.9463 - val_loss: 0.2408 - val_accuracy: 0.9094 - val_IoU: 0.7879 - val_dice_coef: 0.8966 - val_precision: 0.8870 - val_recall: 0.9065 - val_f1_score: 0.8966\n",
            "Epoch 68/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1034 - accuracy: 0.9326 - IoU: 0.8782 - dice_coef: 0.9441 - precision: 0.9462 - recall: 0.9422 - f1_score: 0.9441 - val_loss: 0.2313 - val_accuracy: 0.9113 - val_IoU: 0.7887 - val_dice_coef: 0.8994 - val_precision: 0.8886 - val_recall: 0.9106 - val_f1_score: 0.8994\n",
            "Epoch 69/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0981 - accuracy: 0.9345 - IoU: 0.8838 - dice_coef: 0.9466 - precision: 0.9481 - recall: 0.9452 - f1_score: 0.9466 - val_loss: 0.2366 - val_accuracy: 0.9114 - val_IoU: 0.7930 - val_dice_coef: 0.9004 - val_precision: 0.8815 - val_recall: 0.9203 - val_f1_score: 0.9004\n",
            "Epoch 70/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0938 - accuracy: 0.9362 - IoU: 0.8887 - dice_coef: 0.9490 - precision: 0.9497 - recall: 0.9485 - f1_score: 0.9490 - val_loss: 0.2475 - val_accuracy: 0.9077 - val_IoU: 0.7863 - val_dice_coef: 0.8955 - val_precision: 0.8757 - val_recall: 0.9163 - val_f1_score: 0.8955\n",
            "Epoch 71/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0929 - accuracy: 0.9365 - IoU: 0.8899 - dice_coef: 0.9495 - precision: 0.9499 - recall: 0.9492 - f1_score: 0.9495 - val_loss: 0.2404 - val_accuracy: 0.9081 - val_IoU: 0.7875 - val_dice_coef: 0.8966 - val_precision: 0.8742 - val_recall: 0.9204 - val_f1_score: 0.8966\n",
            "Epoch 72/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0959 - accuracy: 0.9353 - IoU: 0.8866 - dice_coef: 0.9478 - precision: 0.9487 - recall: 0.9469 - f1_score: 0.9478 - val_loss: 0.2302 - val_accuracy: 0.9091 - val_IoU: 0.7916 - val_dice_coef: 0.8986 - val_precision: 0.8758 - val_recall: 0.9228 - val_f1_score: 0.8986\n",
            "Epoch 73/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0917 - accuracy: 0.9370 - IoU: 0.8908 - dice_coef: 0.9501 - precision: 0.9508 - recall: 0.9495 - f1_score: 0.9501 - val_loss: 0.2468 - val_accuracy: 0.9093 - val_IoU: 0.7882 - val_dice_coef: 0.8979 - val_precision: 0.8797 - val_recall: 0.9170 - val_f1_score: 0.8979\n",
            "Epoch 74/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0908 - accuracy: 0.9374 - IoU: 0.8921 - dice_coef: 0.9507 - precision: 0.9512 - recall: 0.9502 - f1_score: 0.9507 - val_loss: 0.2419 - val_accuracy: 0.9085 - val_IoU: 0.7909 - val_dice_coef: 0.8988 - val_precision: 0.8683 - val_recall: 0.9318 - val_f1_score: 0.8988\n",
            "Epoch 75/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0914 - accuracy: 0.9371 - IoU: 0.8915 - dice_coef: 0.9502 - precision: 0.9508 - recall: 0.9499 - f1_score: 0.9502 - val_loss: 0.2326 - val_accuracy: 0.9109 - val_IoU: 0.7919 - val_dice_coef: 0.8996 - val_precision: 0.8837 - val_recall: 0.9163 - val_f1_score: 0.8996\n",
            "Epoch 76/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0903 - accuracy: 0.9375 - IoU: 0.8927 - dice_coef: 0.9509 - precision: 0.9515 - recall: 0.9504 - f1_score: 0.9509 - val_loss: 0.2500 - val_accuracy: 0.9058 - val_IoU: 0.7814 - val_dice_coef: 0.8937 - val_precision: 0.8709 - val_recall: 0.9178 - val_f1_score: 0.8937\n",
            "Epoch 77/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0881 - accuracy: 0.9384 - IoU: 0.8953 - dice_coef: 0.9520 - precision: 0.9527 - recall: 0.9514 - f1_score: 0.9520 - val_loss: 0.2390 - val_accuracy: 0.9107 - val_IoU: 0.7937 - val_dice_coef: 0.9003 - val_precision: 0.8751 - val_recall: 0.9271 - val_f1_score: 0.9003\n",
            "Epoch 78/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0878 - accuracy: 0.9385 - IoU: 0.8956 - dice_coef: 0.9524 - precision: 0.9529 - recall: 0.9520 - f1_score: 0.9524 - val_loss: 0.2448 - val_accuracy: 0.9088 - val_IoU: 0.7873 - val_dice_coef: 0.8978 - val_precision: 0.8789 - val_recall: 0.9175 - val_f1_score: 0.8978\n",
            "Epoch 79/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0908 - accuracy: 0.9373 - IoU: 0.8923 - dice_coef: 0.9507 - precision: 0.9514 - recall: 0.9501 - f1_score: 0.9507 - val_loss: 0.2393 - val_accuracy: 0.9102 - val_IoU: 0.7879 - val_dice_coef: 0.8988 - val_precision: 0.8858 - val_recall: 0.9122 - val_f1_score: 0.8988\n",
            "Epoch 80/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0901 - accuracy: 0.9376 - IoU: 0.8928 - dice_coef: 0.9511 - precision: 0.9519 - recall: 0.9504 - f1_score: 0.9511 - val_loss: 0.2533 - val_accuracy: 0.9086 - val_IoU: 0.7824 - val_dice_coef: 0.8954 - val_precision: 0.8875 - val_recall: 0.9034 - val_f1_score: 0.8954\n",
            "Epoch 81/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0907 - accuracy: 0.9374 - IoU: 0.8922 - dice_coef: 0.9508 - precision: 0.9516 - recall: 0.9500 - f1_score: 0.9508 - val_loss: 0.2540 - val_accuracy: 0.9042 - val_IoU: 0.7817 - val_dice_coef: 0.8933 - val_precision: 0.8551 - val_recall: 0.9357 - val_f1_score: 0.8933\n",
            "Epoch 82/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0880 - accuracy: 0.9384 - IoU: 0.8952 - dice_coef: 0.9522 - precision: 0.9528 - recall: 0.9517 - f1_score: 0.9522 - val_loss: 0.2423 - val_accuracy: 0.9094 - val_IoU: 0.7889 - val_dice_coef: 0.8980 - val_precision: 0.8832 - val_recall: 0.9134 - val_f1_score: 0.8980\n",
            "Epoch 83/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0856 - accuracy: 0.9394 - IoU: 0.8981 - dice_coef: 0.9536 - precision: 0.9541 - recall: 0.9532 - f1_score: 0.9536 - val_loss: 0.2510 - val_accuracy: 0.9081 - val_IoU: 0.7847 - val_dice_coef: 0.8962 - val_precision: 0.8743 - val_recall: 0.9194 - val_f1_score: 0.8962\n",
            "Epoch 84/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0849 - accuracy: 0.9396 - IoU: 0.8991 - dice_coef: 0.9541 - precision: 0.9546 - recall: 0.9537 - f1_score: 0.9541 - val_loss: 0.2520 - val_accuracy: 0.9076 - val_IoU: 0.7850 - val_dice_coef: 0.8960 - val_precision: 0.8724 - val_recall: 0.9211 - val_f1_score: 0.8960\n",
            "Epoch 85/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0859 - accuracy: 0.9392 - IoU: 0.8978 - dice_coef: 0.9533 - precision: 0.9538 - recall: 0.9529 - f1_score: 0.9533 - val_loss: 0.2369 - val_accuracy: 0.9111 - val_IoU: 0.7938 - val_dice_coef: 0.9003 - val_precision: 0.8813 - val_recall: 0.9204 - val_f1_score: 0.9003\n",
            "Epoch 86/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0968 - accuracy: 0.9351 - IoU: 0.8853 - dice_coef: 0.9475 - precision: 0.9495 - recall: 0.9458 - f1_score: 0.9475 - val_loss: 0.2262 - val_accuracy: 0.9119 - val_IoU: 0.7913 - val_dice_coef: 0.8999 - val_precision: 0.8899 - val_recall: 0.9102 - val_f1_score: 0.8999\n",
            "Epoch 87/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0978 - accuracy: 0.9347 - IoU: 0.8843 - dice_coef: 0.9473 - precision: 0.9489 - recall: 0.9460 - f1_score: 0.9473 - val_loss: 0.2398 - val_accuracy: 0.9056 - val_IoU: 0.7797 - val_dice_coef: 0.8933 - val_precision: 0.8672 - val_recall: 0.9213 - val_f1_score: 0.8933\n",
            "Epoch 88/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0890 - accuracy: 0.9380 - IoU: 0.8941 - dice_coef: 0.9514 - precision: 0.9521 - recall: 0.9509 - f1_score: 0.9514 - val_loss: 0.2506 - val_accuracy: 0.9100 - val_IoU: 0.7870 - val_dice_coef: 0.8975 - val_precision: 0.8862 - val_recall: 0.9092 - val_f1_score: 0.8975\n",
            "Epoch 89/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0836 - accuracy: 0.9401 - IoU: 0.9006 - dice_coef: 0.9547 - precision: 0.9551 - recall: 0.9544 - f1_score: 0.9547 - val_loss: 0.2428 - val_accuracy: 0.9101 - val_IoU: 0.7904 - val_dice_coef: 0.8987 - val_precision: 0.8835 - val_recall: 0.9145 - val_f1_score: 0.8987\n",
            "Epoch 90/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0823 - accuracy: 0.9407 - IoU: 0.9023 - dice_coef: 0.9555 - precision: 0.9557 - recall: 0.9554 - f1_score: 0.9555 - val_loss: 0.2859 - val_accuracy: 0.9001 - val_IoU: 0.7645 - val_dice_coef: 0.8852 - val_precision: 0.8685 - val_recall: 0.9027 - val_f1_score: 0.8852\n",
            "Epoch 91/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0837 - accuracy: 0.9400 - IoU: 0.9007 - dice_coef: 0.9546 - precision: 0.9551 - recall: 0.9543 - f1_score: 0.9546 - val_loss: 0.2653 - val_accuracy: 0.9104 - val_IoU: 0.7888 - val_dice_coef: 0.8986 - val_precision: 0.8868 - val_recall: 0.9109 - val_f1_score: 0.8986\n",
            "Epoch 92/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0812 - accuracy: 0.9410 - IoU: 0.9033 - dice_coef: 0.9560 - precision: 0.9564 - recall: 0.9556 - f1_score: 0.9560 - val_loss: 0.2482 - val_accuracy: 0.9097 - val_IoU: 0.7865 - val_dice_coef: 0.8980 - val_precision: 0.8840 - val_recall: 0.9126 - val_f1_score: 0.8980\n",
            "Epoch 93/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0810 - accuracy: 0.9411 - IoU: 0.9036 - dice_coef: 0.9561 - precision: 0.9566 - recall: 0.9558 - f1_score: 0.9561 - val_loss: 0.2683 - val_accuracy: 0.9076 - val_IoU: 0.7842 - val_dice_coef: 0.8956 - val_precision: 0.8754 - val_recall: 0.9169 - val_f1_score: 0.8956\n",
            "Epoch 94/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0806 - accuracy: 0.9413 - IoU: 0.9041 - dice_coef: 0.9565 - precision: 0.9568 - recall: 0.9562 - f1_score: 0.9565 - val_loss: 0.2731 - val_accuracy: 0.9067 - val_IoU: 0.7813 - val_dice_coef: 0.8942 - val_precision: 0.8719 - val_recall: 0.9180 - val_f1_score: 0.8942\n",
            "Epoch 95/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.1455 - accuracy: 0.9172 - IoU: 0.8365 - dice_coef: 0.9224 - precision: 0.9297 - recall: 0.9162 - f1_score: 0.9224 - val_loss: 0.2295 - val_accuracy: 0.9061 - val_IoU: 0.7838 - val_dice_coef: 0.8934 - val_precision: 0.8740 - val_recall: 0.9138 - val_f1_score: 0.8934\n",
            "Epoch 96/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0977 - accuracy: 0.9347 - IoU: 0.8842 - dice_coef: 0.9470 - precision: 0.9481 - recall: 0.9461 - f1_score: 0.9470 - val_loss: 0.2440 - val_accuracy: 0.9086 - val_IoU: 0.7853 - val_dice_coef: 0.8961 - val_precision: 0.8815 - val_recall: 0.9113 - val_f1_score: 0.8961\n",
            "Epoch 97/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0845 - accuracy: 0.9398 - IoU: 0.8991 - dice_coef: 0.9542 - precision: 0.9547 - recall: 0.9538 - f1_score: 0.9542 - val_loss: 0.2622 - val_accuracy: 0.9074 - val_IoU: 0.7835 - val_dice_coef: 0.8941 - val_precision: 0.8796 - val_recall: 0.9093 - val_f1_score: 0.8941\n",
            "Epoch 98/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0802 - accuracy: 0.9414 - IoU: 0.9044 - dice_coef: 0.9568 - precision: 0.9571 - recall: 0.9566 - f1_score: 0.9568 - val_loss: 0.2591 - val_accuracy: 0.9076 - val_IoU: 0.7860 - val_dice_coef: 0.8952 - val_precision: 0.8761 - val_recall: 0.9153 - val_f1_score: 0.8952\n",
            "Epoch 99/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0779 - accuracy: 0.9424 - IoU: 0.9074 - dice_coef: 0.9580 - precision: 0.9580 - recall: 0.9580 - f1_score: 0.9580 - val_loss: 0.2785 - val_accuracy: 0.9072 - val_IoU: 0.7838 - val_dice_coef: 0.8944 - val_precision: 0.8779 - val_recall: 0.9117 - val_f1_score: 0.8944\n",
            "Epoch 100/100\n",
            "208/208 [==============================] - 12s 57ms/step - loss: 0.0770 - accuracy: 0.9427 - IoU: 0.9084 - dice_coef: 0.9585 - precision: 0.9587 - recall: 0.9584 - f1_score: 0.9585 - val_loss: 0.2785 - val_accuracy: 0.9057 - val_IoU: 0.7807 - val_dice_coef: 0.8928 - val_precision: 0.8705 - val_recall: 0.9165 - val_f1_score: 0.8928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/archive/final_Unet_model_75.h5')"
      ],
      "metadata": {
        "id": "SxQQDjyGEP-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_samples(images, masks, preds, num_samples=5):\n",
        "    fig, axes = plt.subplots(nrows=num_samples, ncols=3, figsize=(15, num_samples * 5))  # Adjusted figsize\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Original Image\n",
        "        axes[i, 0].imshow(images[i])\n",
        "        axes[i, 0].set_title(\"Image\")\n",
        "        axes[i, 0].axis(\"off\")\n",
        "\n",
        "        # Ground Truth Mask\n",
        "        axes[i, 1].imshow(masks[i], cmap='gray')\n",
        "        axes[i, 1].set_title(\"Ground Truth\")\n",
        "        axes[i, 1].axis(\"off\")\n",
        "\n",
        "        # Prediction (Without Overlay)\n",
        "        axes[i, 2].imshow(preds[i], cmap='gray')  # Show prediction in grayscale\n",
        "        axes[i, 2].set_title(\"Prediction\")\n",
        "        axes[i, 2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "test_samples = test_images[:10]\n",
        "ground_truth_masks = test_masks[:10]\n",
        "predictions =model.predict(test_samples)\n",
        "\n",
        "predictions = np.squeeze(predictions, axis=3)\n",
        "predictions = (predictions > 0.5).astype(np.uint8)\n",
        "display_samples(test_samples, ground_truth_masks, predictions)"
      ],
      "metadata": {
        "id": "2mmZ05eTF6Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "accuracy_values = history.history['accuracy']\n",
        "val_accuracy_values = history.history['val_accuracy']\n",
        "iou_values = history.history['IoU']\n",
        "dice_values = history.history['dice_coef']\n",
        "precision_values = history.history['precision']\n",
        "recall_values = history.history['recall']\n",
        "f1_values = history.history['f1_score']"
      ],
      "metadata": {
        "id": "OGYLKqrdE0MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, loss_values, 'r', label='Training Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ntgMXeEahaj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, accuracy_values, 'g', label='Training Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "80IY0Oa3hjIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(3, 3, figsize=(15, 8))\n",
        "\n",
        "axs[0, 0].plot(epochs, accuracy_values, 'g', label='Training Accuracy')\n",
        "axs[0, 0].set_title('Training Accuracy')\n",
        "axs[0, 0].set_xlabel('Epochs')\n",
        "axs[0, 0].set_ylabel('Accuracy')\n",
        "axs[0, 0].legend()\n",
        "\n",
        "axs[0, 1].plot(epochs, loss_values, 'r', label='Training Loss')\n",
        "axs[0, 1].set_title('Training Loss')\n",
        "axs[0, 1].set_xlabel('Epochs')\n",
        "axs[0, 1].set_ylabel('Loss')\n",
        "axs[0, 1].legend()\n",
        "\n",
        "axs[0, 2].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "axs[0, 2].set_title('Validation Loss')\n",
        "axs[0, 2].set_xlabel('Epochs')\n",
        "axs[0, 2].set_ylabel('Loss')\n",
        "axs[0, 2].legend()\n",
        "\n",
        "axs[1, 0].plot(epochs, val_accuracy_values, 'k', label='Validation Accuracy')\n",
        "axs[1, 0].set_title('Validation Accuracy')\n",
        "axs[1, 0].set_xlabel('Epochs')\n",
        "axs[1, 0].set_ylabel('Accuracy')\n",
        "axs[1, 0].legend()\n",
        "\n",
        "axs[1, 1].plot(epochs, iou_values, 'y', label='IoU')\n",
        "axs[1, 1].set_title('IoU')\n",
        "axs[1, 1].set_xlabel('Epochs')\n",
        "axs[1, 1].set_ylabel('Metric Value')\n",
        "axs[1, 1].legend()\n",
        "\n",
        "axs[1, 2].plot(epochs, dice_values, 'c', label='Dice Coefficient')\n",
        "axs[1, 2].set_title('Dice Coefficient')\n",
        "axs[1, 2].set_xlabel('Epochs')\n",
        "axs[1, 2].set_ylabel('Metric Value')\n",
        "axs[1, 2].legend()\n",
        "\n",
        "axs[2, 0].plot(epochs, precision_values, 'm', label='Precision')\n",
        "axs[2, 0].set_title('Precision')\n",
        "axs[2, 0].set_xlabel('Epochs')\n",
        "axs[2, 0].set_ylabel('Metric Value')\n",
        "axs[2, 0].legend()\n",
        "\n",
        "axs[2, 1].plot(epochs, recall_values, 'b', label='Recall')\n",
        "axs[2, 1].set_title('Recall')\n",
        "axs[2, 1].set_xlabel('Epochs')\n",
        "axs[2, 1].set_ylabel('Metric Value')\n",
        "axs[2, 1].legend()\n",
        "\n",
        "axs[2, 2].plot(epochs, f1_values, 'k', label='F1 Score')\n",
        "axs[2, 2].set_title('F1 Score')\n",
        "axs[2, 2].set_xlabel('Epochs')\n",
        "axs[2, 2].set_ylabel('Metric Value')\n",
        "axs[2, 2].legend()\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AbbGlTl3hnBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Loss:\",loss_values)\n",
        "print(\"Validation Loss:\",val_loss)\n",
        "print(\"Training Accuracy:\",accuracy_values)\n",
        "print(\"Valdiation Accuracy:\",val_accuracy_values)\n",
        "print(\"IOU:\",iou_values)\n",
        "print(\"Dice Cofficiexnt:\",dice_values)\n",
        "print(\"Precision:\",precision_values)\n",
        "print(\"Recall:\", recall_values)\n",
        "print(\"F1 score:\",f1_values)\n"
      ],
      "metadata": {
        "id": "_-wWDmBciTA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9cc2dd-772d-4791-8fbe-3f1f6dd8568f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: [0.47252342104911804, 0.37582504749298096, 0.3656098544597626, 0.3357357978820801, 0.31906649470329285, 0.3519968092441559, 0.33616888523101807, 0.30712929368019104, 0.2962341010570526, 0.29259541630744934, 0.3025435209274292, 0.28380370140075684, 0.28684091567993164, 0.2750934362411499, 0.2655487358570099, 0.26147472858428955, 0.2541562020778656, 0.2518266439437866, 0.249764546751976, 0.2494651824235916, 0.2540821433067322, 0.24239253997802734, 0.24056315422058105, 0.23819032311439514, 0.24161118268966675, 0.23317766189575195, 0.23046809434890747, 0.2250799834728241, 0.22336018085479736, 0.22777199745178223, 0.2197035551071167, 0.21647725999355316, 0.21179211139678955, 0.2210625410079956, 0.20909172296524048, 0.2060663104057312, 0.20608948171138763, 0.20385819673538208, 0.19496646523475647, 0.21124491095542908, 0.19160236418247223, 0.18604247272014618, 0.1819220632314682, 0.17956846952438354, 0.175352543592453, 0.21980789303779602, 0.18616676330566406, 0.19111698865890503, 0.16519708931446075, 0.16008631885051727, 0.1545349508523941, 0.14976394176483154, 0.1465131789445877, 0.15066786110401154, 0.14511321485042572, 0.14092199504375458, 0.13943850994110107, 0.13617117702960968, 0.13902410864830017, 0.13040313124656677, 0.1259223222732544, 0.12379463762044907, 0.12324850261211395, 0.13861368596553802, 0.12936042249202728, 0.12470627576112747, 0.120208740234375, 0.11557720601558685, 0.11557058244943619, 0.11448201537132263, 0.11355393379926682, 0.11365421116352081, 0.11374913901090622, 0.11089040338993073, 0.10914023965597153]\n",
            "Validation Loss: [0.38270288705825806, 0.2953839898109436, 0.2986673414707184, 0.263278067111969, 0.27195265889167786, 0.280074805021286, 0.24896426498889923, 0.22858422994613647, 0.21939021348953247, 0.23194870352745056, 0.22104230523109436, 0.26280686259269714, 0.2220226228237152, 0.23356442153453827, 0.21054504811763763, 0.20318618416786194, 0.2015177607536316, 0.1981750726699829, 0.21099142730236053, 0.2472139298915863, 0.19450809061527252, 0.19734235107898712, 0.2064855992794037, 0.175441175699234, 0.17460300028324127, 0.17395585775375366, 0.18708159029483795, 0.19585289061069489, 0.19451366364955902, 0.17969253659248352, 0.20169579982757568, 0.17616721987724304, 0.17557264864444733, 0.18229566514492035, 0.18686792254447937, 0.17728443443775177, 0.19870725274085999, 0.17741377651691437, 0.18064364790916443, 0.1882125437259674, 0.18837375938892365, 0.17387235164642334, 0.17755946516990662, 0.20747259259223938, 0.19339995086193085, 0.18584775924682617, 0.207800954580307, 0.2020532637834549, 0.18216222524642944, 0.18906666338443756, 0.19536453485488892, 0.18112099170684814, 0.19036456942558289, 0.18630796670913696, 0.20020060241222382, 0.1851736158132553, 0.18470393121242523, 0.19524464011192322, 0.18715324997901917, 0.19439111649990082, 0.20606248080730438, 0.1955917775630951, 0.192384734749794, 0.20478570461273193, 0.2099749743938446, 0.18859556317329407, 0.21253223717212677, 0.20210720598697662, 0.19624173641204834, 0.2323412448167801, 0.22140057384967804, 0.19040216505527496, 0.21277298033237457, 0.2087855339050293, 0.21164919435977936]\n",
            "Training Accuracy: [0.7616877555847168, 0.8134159445762634, 0.8166524767875671, 0.8358685374259949, 0.8439255356788635, 0.8281559944152832, 0.8362330794334412, 0.8509382605552673, 0.8570674657821655, 0.8588545322418213, 0.8525505661964417, 0.8623927235603333, 0.8610354065895081, 0.8664246797561646, 0.8711008429527283, 0.8725076913833618, 0.8755974173545837, 0.8764299154281616, 0.8773581981658936, 0.8777312636375427, 0.8755577802658081, 0.8811056017875671, 0.8814351558685303, 0.8827171921730042, 0.880807638168335, 0.8841605186462402, 0.8855831623077393, 0.8880391716957092, 0.8887391090393066, 0.8866237998008728, 0.889910876750946, 0.8913804292678833, 0.8930004239082336, 0.8893963098526001, 0.8942909836769104, 0.8954861164093018, 0.8950243592262268, 0.8955256938934326, 0.8992306590080261, 0.8925989866256714, 0.9002740383148193, 0.902249813079834, 0.9032315611839294, 0.9043317437171936, 0.9057567715644836, 0.8888407945632935, 0.9014853835105896, 0.8994058966636658, 0.9093404412269592, 0.911111056804657, 0.9131248593330383, 0.9147566556930542, 0.9158746004104614, 0.9144892692565918, 0.9163980484008789, 0.9181211590766907, 0.9186481833457947, 0.919746994972229, 0.9187560677528381, 0.9220789670944214, 0.9237465262413025, 0.9245915412902832, 0.924765944480896, 0.9189814925193787, 0.9224042892456055, 0.924210250377655, 0.9258953332901001, 0.927711009979248, 0.9276831746101379, 0.9280689358711243, 0.9284271001815796, 0.9284068942070007, 0.9283517003059387, 0.9295200705528259, 0.9301379919052124]\n",
            "Valdiation Accuracy: [0.821562647819519, 0.8681772351264954, 0.8605283498764038, 0.8826451897621155, 0.8750352263450623, 0.8651022911071777, 0.8824315667152405, 0.8969637155532837, 0.8981049656867981, 0.8965522646903992, 0.898407518863678, 0.8812645077705383, 0.8966416716575623, 0.8978545069694519, 0.9064667820930481, 0.9077606201171875, 0.9075385928153992, 0.9093496203422546, 0.9080747365951538, 0.8880541324615479, 0.9075570106506348, 0.9090697169303894, 0.9025663137435913, 0.9121325016021729, 0.9162361025810242, 0.9147917628288269, 0.9121004343032837, 0.907410204410553, 0.9157556891441345, 0.913483738899231, 0.9059779644012451, 0.9170658588409424, 0.9183796644210815, 0.9124219417572021, 0.9145360589027405, 0.9160940051078796, 0.9058985114097595, 0.9184396862983704, 0.9144355654716492, 0.9122809171676636, 0.9099463224411011, 0.9184670448303223, 0.9168775081634521, 0.9059195518493652, 0.9094290733337402, 0.9141650795936584, 0.9063625931739807, 0.9084314703941345, 0.9152742624282837, 0.9135221242904663, 0.9073149561882019, 0.9150711297988892, 0.9133269190788269, 0.9129996299743652, 0.9105414152145386, 0.9167338609695435, 0.9158856868743896, 0.9120283722877502, 0.9156635999679565, 0.9158856868743896, 0.9140035510063171, 0.9136620759963989, 0.9145849943161011, 0.9101336002349854, 0.9100073575973511, 0.913700520992279, 0.9137552380561829, 0.9151985049247742, 0.914188802242279, 0.9131853580474854, 0.9118562936782837, 0.9177140593528748, 0.9106366634368896, 0.9144923686981201, 0.914158284664154]\n",
            "IOU: [0.535430908203125, 0.6210498213768005, 0.6256129145622253, 0.6586907505989075, 0.6716859340667725, 0.6447151899337769, 0.6558457612991333, 0.6840254664421082, 0.6960651874542236, 0.7032423615455627, 0.6884030103683472, 0.7094911336898804, 0.7054048180580139, 0.7145205140113831, 0.7253456711769104, 0.7282777428627014, 0.7345892190933228, 0.7375749349594116, 0.7396039366722107, 0.7401654720306396, 0.7344719171524048, 0.7482842803001404, 0.7488295435905457, 0.7519205808639526, 0.7458425164222717, 0.7551661133766174, 0.759203314781189, 0.7649163007736206, 0.7669376730918884, 0.7614945769309998, 0.7703794240951538, 0.7734079360961914, 0.776593804359436, 0.7683289647102356, 0.7800354361534119, 0.7828731536865234, 0.7804991006851196, 0.7834312915802002, 0.7912889719009399, 0.7761313915252686, 0.7936013340950012, 0.7990419864654541, 0.800770103931427, 0.8034624457359314, 0.8075112700462341, 0.7670148611068726, 0.7967789173126221, 0.7921931147575378, 0.8161627650260925, 0.8204914927482605, 0.8253880739212036, 0.8294247388839722, 0.8327227830886841, 0.8289614319801331, 0.8338605165481567, 0.8384718298912048, 0.8395299315452576, 0.8429186344146729, 0.8401407599449158, 0.8488770127296448, 0.8537073731422424, 0.8560575246810913, 0.8569775223731995, 0.8407604694366455, 0.8499149084091187, 0.8550306558609009, 0.8596954941749573, 0.8650007843971252, 0.8647652864456177, 0.8661152124404907, 0.8670151829719543, 0.8668817281723022, 0.8669136762619019, 0.869953453540802, 0.8718670606613159]\n",
            "Dice Cofficiexnt: [0.6971597075462341, 0.7781113982200623, 0.7810223698616028, 0.8077236413955688, 0.8191877603530884, 0.7935675978660583, 0.8071850538253784, 0.8280043005943298, 0.8370077610015869, 0.8404557704925537, 0.83162921667099, 0.8452569246292114, 0.8431678414344788, 0.8513126969337463, 0.8573743104934692, 0.8596490621566772, 0.8640645146369934, 0.8661118745803833, 0.8666372299194336, 0.8669110536575317, 0.8638597726821899, 0.8722714185714722, 0.872797966003418, 0.8744068741798401, 0.8715232014656067, 0.8764019012451172, 0.8782370090484619, 0.8816527724266052, 0.8820794820785522, 0.8800528049468994, 0.8850994110107422, 0.8870118260383606, 0.8886038661003113, 0.8837007284164429, 0.8912407159805298, 0.8930178284645081, 0.8914996385574341, 0.892234742641449, 0.8976355195045471, 0.8887600302696228, 0.8991785645484924, 0.9018277525901794, 0.903039813041687, 0.904847264289856, 0.9062153100967407, 0.8824314475059509, 0.9006538391113281, 0.8970845937728882, 0.9110915064811707, 0.9142088294029236, 0.916609525680542, 0.9187818169593811, 0.9204779863357544, 0.91846764087677, 0.9212133884429932, 0.9235548377037048, 0.9242738485336304, 0.9262705445289612, 0.9246503114700317, 0.9290933609008789, 0.9310789704322815, 0.9323780536651611, 0.9331846833229065, 0.9246848225593567, 0.9296121597290039, 0.9323100447654724, 0.9343617558479309, 0.9369765520095825, 0.9371340870857239, 0.9378020763397217, 0.9379419088363647, 0.938059389591217, 0.9380525350570679, 0.9394503831863403, 0.940578818321228]\n",
            "Precision: [0.7457842230796814, 0.8142110109329224, 0.8187423348426819, 0.8403300046920776, 0.8508338332176208, 0.8382211923599243, 0.8447905778884888, 0.8642253875732422, 0.871471107006073, 0.8717867732048035, 0.8679428696632385, 0.8750433325767517, 0.8736125230789185, 0.8804396390914917, 0.8828939199447632, 0.8828839659690857, 0.8873659372329712, 0.8867050409317017, 0.8870440125465393, 0.8865474462509155, 0.8873077630996704, 0.8906930088996887, 0.890417218208313, 0.8922220468521118, 0.8911734819412231, 0.8931736350059509, 0.8944164514541626, 0.8969132304191589, 0.8983507752418518, 0.8963062763214111, 0.8981894850730896, 0.9005709886550903, 0.9021559357643127, 0.8993546366691589, 0.903458833694458, 0.9057307839393616, 0.9052533507347107, 0.9051972031593323, 0.9103537201881409, 0.9046010971069336, 0.9108392000198364, 0.9124161601066589, 0.9146560430526733, 0.9148774743080139, 0.9163292646408081, 0.8987870812416077, 0.9125477075576782, 0.9108787178993225, 0.9199545979499817, 0.9220578074455261, 0.9237182140350342, 0.9255282878875732, 0.9263923168182373, 0.9257020354270935, 0.9277589321136475, 0.9289028644561768, 0.9299119114875793, 0.9310598969459534, 0.9300076961517334, 0.9328308701515198, 0.9343016743659973, 0.9353286027908325, 0.9357286095619202, 0.9302523732185364, 0.9330794811248779, 0.9357386827468872, 0.9366705417633057, 0.9388061761856079, 0.9388728737831116, 0.9393647909164429, 0.9394410848617554, 0.9395841360092163, 0.9397677183151245, 0.9405408501625061, 0.9417076110839844]\n",
            "Recall: [0.6995492577552795, 0.7603467702865601, 0.7653041481971741, 0.785869300365448, 0.7956784963607788, 0.7732718586921692, 0.7811405658721924, 0.7996295690536499, 0.8095405101776123, 0.8155845999717712, 0.8050447106361389, 0.8208137154579163, 0.8194182515144348, 0.8275607228279114, 0.8359050750732422, 0.8396428227424622, 0.8439074158668518, 0.8480212092399597, 0.8492828607559204, 0.8500931859016418, 0.8438336849212646, 0.856349527835846, 0.8576247096061707, 0.8589878678321838, 0.8549346327781677, 0.8619891405105591, 0.8643850684165955, 0.8680874109268188, 0.8678839802742004, 0.8663693070411682, 0.8735682368278503, 0.8747573494911194, 0.8768084049224854, 0.87026447057724, 0.8803411722183228, 0.8820391297340393, 0.8794604539871216, 0.8810562491416931, 0.8864604234695435, 0.8750152587890625, 0.8886001110076904, 0.8921940326690674, 0.892528772354126, 0.8957783579826355, 0.8969092965126038, 0.8694754838943481, 0.8900876641273499, 0.8849189281463623, 0.903030514717102, 0.9070022106170654, 0.9099974036216736, 0.9124718904495239, 0.9149640798568726, 0.9117094278335571, 0.9151521921157837, 0.9186449646949768, 0.9189857244491577, 0.9218186140060425, 0.919785737991333, 0.9255717992782593, 0.9280765056610107, 0.9295835494995117, 0.9308353662490845, 0.9196382164955139, 0.9265310764312744, 0.9291023015975952, 0.9322623610496521, 0.9352944493293762, 0.9355577826499939, 0.9364205598831177, 0.936600387096405, 0.9366682767868042, 0.9365295171737671, 0.9385913610458374, 0.9395690560340881]\n",
            "F1 score: [0.6971591114997864, 0.7781108617782593, 0.7810219526290894, 0.8077231049537659, 0.8191874027252197, 0.7935668230056763, 0.807184636592865, 0.8280039429664612, 0.837007462978363, 0.8404553532600403, 0.8316287398338318, 0.8452566862106323, 0.8431675434112549, 0.8513123989105225, 0.857373833656311, 0.859648585319519, 0.8640641570091248, 0.8661113977432251, 0.8666369318962097, 0.8669108152389526, 0.8638595342636108, 0.8722711205482483, 0.8727977275848389, 0.8744065165519714, 0.8715226650238037, 0.8764016032218933, 0.8782366514205933, 0.8816525340080261, 0.8820790648460388, 0.8800525069236755, 0.8850991129875183, 0.8870115280151367, 0.8886037468910217, 0.8837004899978638, 0.8912404179573059, 0.8930177092552185, 0.891499400138855, 0.8922344446182251, 0.8976351022720337, 0.8887599110603333, 0.8991785049438477, 0.9018273949623108, 0.9030395150184631, 0.9048470258712769, 0.9062151312828064, 0.8824310898780823, 0.9006535410881042, 0.8970844745635986, 0.9110913872718811, 0.9142086505889893, 0.9166094064712524, 0.9187816381454468, 0.920477569103241, 0.9184675216674805, 0.9212131500244141, 0.9235547184944153, 0.9242736101150513, 0.9262703657150269, 0.9246501326560974, 0.929093062877655, 0.9310788512229919, 0.932377815246582, 0.9331843852996826, 0.9246847629547119, 0.9296121597290039, 0.9323097467422485, 0.9343617558479309, 0.9369763135910034, 0.9371339082717896, 0.9378020167350769, 0.9379416704177856, 0.9380592703819275, 0.9380524158477783, 0.9394500255584717, 0.9405787587165833]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXZb3HJDZcr6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}